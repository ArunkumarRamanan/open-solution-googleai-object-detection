project: neptune-ml/Google-Ai-Object-Detection-Challenge

name: google AI object detection
tags: [solution-1, batch-2, eval]

metric:
  channel: 'MAP'
  goal: maximize

#Comment out if not in Cloud Environment
#pip-requirements-file: requirements.txt

exclude:
  - .git
  - .idea
  - .ipynb_checkpoints
  - output
  - imgs
  - neptune.log
  - offline_job.log
  - notebooks

parameters:
# Data Paths
  train_imgs_dir: ''
  test_imgs_dir: ''
  annotations_filepath: ''
  annotations_human_labels_filepath: ''
  bbox_hierarchy_filepath: ''
  valid_ids_filepath: ''
  sample_submission: ''
  experiment_dir:  ''
  class_mappings_filepath: ''
  metadata_filepath: ''

# Execution
  clean_experiment_directory_before_training: 0
  num_workers: 4
  num_threads: 100
  load_in_memory: 0
  pin_memory: 1
  default_valid_ids: 1
  loader_mode: resize
  stream_mode: 0
  validate_with_map: 1
  small_annotations_size: 20
  kaggle_message: 'solution-1'

# General parameters
  sampler_name: 'aspect ratio'     # from {'fixed', 'aspect ratio'}
  even_class_sampling: 1
  fixed_h: 512
  fixed_w: 512
  short_dim: 640 #512
  long_dim: 960 #896
  image_channels: 3
  pad_method: 'resize'
  use_suppression: 0
  max_annotation_per_class: 0
  desired_class_subset: "['Serving tray',
 'Binoculars',
 'Slow cooker',
 'Cricket ball',
 'Tick',
 'Crutch',
 'Oboe',
 'Beaker',
 'Alarm clock',
 'Stretcher',
 'Envelope',
 'Salt and pepper shakers',
 'Food processor',
 'Bench',
 'Digital clock',
 'Wrench',
 'Paper towel',
 'Harpsichord',
 'Cutting board',
 'Mixer',
 'Guacamole',
 'Porcupine',
 'Harp',
 'Blender',
 'Shower',
 'Lynx',
 'Treadmill',
 'Ruler',
 'Adhesive tape',
 'Blue jay',
 'Burrito',
 'Printer',
 'Dog bed',
 'Submarine sandwich',
 'Centipede',
 'Power plugs and sockets',
 'Drinking straw',
 'Rugby ball',
 'Pretzel',
 'Wood-burning stove',
 'Snowplow',
 'Seahorse',
 'Common fig',
 'Coffeemaker',
 'Punching bag',
 'Cake stand',
 'Towel',
 'Stationary bicycle',
 'Pitcher',
 'Kitchen knife',
 'Bathroom cabinet',
 'Flute',
 'Popcorn',
 'Limousine',
 'Snowmobile',
 'Dagger',
 'Filing cabinet',
 'Artichoke',
 'Toilet paper',
 'Frying pan',
 'Raccoon',
 'Honeycomb',
 'Canary',
 'Asparagus',
 'Stop sign',
 'Organ',
 'Scissors',
 'Dumbbell',
 'Picnic basket',
 'Mango',
 'Fire hydrant',
 'Corded phone',
 'Golf ball',
 'Cabbage',
 'Bidet',
 'Croissant',
 'Ambulance',
 'Sewing machine',
 'Seat belt',
 'Infant bed',
 'Ceiling fan',
 'Hot dog',
 'Microwave oven',
 'Nail']"

# Retina parameters (multi-output)
  encoder_depth: 50
  num_classes: 100
  pretrained_encoder: 1
  pi: 0.01
  aspect_ratios: '[1/2., 1/1., 2/1.]'
  scale_ratios: '[1., pow(2,1/3.), pow(2,2/3.)]'

# Training schedule
  epochs_nr: 1000
  batch_size_train: 8
  batch_size_inference: 8
  lr: 0.00001
  momentum: 0.9
  gamma: 1.0
  patience: 100
  lr_factor: 0.3
  lr_patience: 30
  training_sample_size: 10000
  validation_sample_size: 2000

# Regularization
  use_batch_norm: 1
  l2_reg_conv: 0.0001
  l2_reg_dense: 0.0
  dropout_conv: 0.1
  dropout_dense: 0.0

# Postprocessing
  classification_threshold: 0.05
  nms_threshold: 0.5
