project: neptune-ml/Google-AI-Object-Detection-Challenge

name: google-ai-object-detection
tags: [solution-1, batch_1, retrain]

metric:
  channel: 'MAP'
  goal: maximize

#Comment out if not in Cloud Environment
#pip-requirements-file: requirements.txt

exclude:
  - .git
  - .idea
  - .ipynb_checkpoints
  - output
  - imgs
  - neptune.log
  - offline_job.log
  - notebooks

parameters:
# Data Paths
  train_imgs_dir: '/mnt/ml-team/open-images-v4/bounding-boxes/train/'
  test_imgs_dir: '/mnt/ml-team/open-images-v4/bounding-boxes/test_challenge_2018/'
  annotations_filepath: '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/annotations/challenge-2018-train-annotations-bbox.csv'
  annotations_human_labels_filepath: '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/annotations/challenge-2018-train-annotations-human-imagelabels.csv'
  bbox_hierarchy_filepath: '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/metadata/bbox_labels_500_hierarchy.json'
  valid_ids_filepath: '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/metadata/challenge-2018-image-ids-valset-od.csv'
  experiment_dir:  '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/kuba/experiments/batch_1'
  class_mappings_filepath: '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/metadata/challenge-2018-class-descriptions-500.csv'
  metadata_filepath: '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/files/metadata.csv'
  sample_submission: '/mnt/ml-team/minerva/open-solutions/googleai-object-detection/data/sample_submission.csv'

# Execution
  clean_experiment_directory_before_training: 0
  num_workers: 4
  num_threads: 100
  load_in_memory: 0
  pin_memory: 1
  default_valid_ids: 1
  loader_mode: resize
  stream_mode: 0
  validate_with_map: 1
  small_annotations_size: 20
  kaggle_message: 'solution-1'

# General parameters
  sampler_name: 'aspect ratio'     # from {'fixed', 'aspect ratio'}
  even_class_sampling: 1
  fixed_h: 512
  fixed_w: 512
  short_dim: 640 #512
  long_dim: 960 #896
  image_channels: 3
  pad_method: 'resize'
  use_suppression: 0
  max_annotation_per_class: 1000000
  desired_class_subset: "['Pressure cooker',
 'Torch',
 'Winter melon',
 'Spatula',
 'Toaster',
 'Measuring cup',
 'Ring binder',
 'Screwdriver',
 'Flashlight',
 'Light switch']"

# Retina parameters (multi-output)
  encoder_depth: 50
  num_classes: 100
  pretrained_encoder: 1
  pi: 0.01
  aspect_ratios: '[1/2., 1/1., 2/1.]'
  scale_ratios: '[1., pow(2,1/3.), pow(2,2/3.)]'

# Training schedule
  epochs_nr: 1000
  batch_size_train: 8
  batch_size_inference: 1
  lr: 0.00001
  momentum: 0.9
  gamma: 1.0
  patience: 100
  lr_factor: 0.3
  lr_patience: 30
  training_sample_size: 10000
  validation_sample_size: 2000

# Regularization
  use_batch_norm: 1
  l2_reg_conv: 0.0001
  l2_reg_dense: 0.0
  dropout_conv: 0.1
  dropout_dense: 0.0

# Postprocessing
  classification_threshold: 0.05
  nms_threshold: 0.5
